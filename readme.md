# Esperimento sulla moralità di GPT-4

Questo è un esperimento che ho condotto sulla moralità di GPT-4.

L'ho messo di fronte a una serie di scenari ipotetici di moralità dubbia o contrastante, con lo scopo di capire come si comporterebbe in un ventaglio di situazioni in cui è richiesto bilanciare pro e contro, o scegliere il "male minore".

Ci sono due domande alle quali ho voluto dare risposta:

## GPT-4 ha una moralità migliore o peggiore rispetto a un essere umano medio?

Le fantasie sulla "AI cattiva" stile Terminator divampano. In realtà, l'Intelligenza Artificiale si sta evolvendo in maniera molto diversa rispetto a quanto ipotizzavano gli sceneggiatori di Hollywood 40 anni fa.

Visto che GPT-4 è in grado di elaborare dati e simulare moralità in maniera convincente, è possibile già ora porre all'Intelligenza Artificiale una serie di quesiti morali e osservare il suo comportamento. Successivamente, è possibile speculare se la decisione presa da GPT-4 è più o meno morale rispetto a quanto vediamo nei politici umani ogni giorno.

L'ipotesi è che, non avendo emozioni o sentimenti, GPT-4 non farà altro che rispettare le istruzioni sulle quali è stato programmato. Quindi non può avere nessun motivo ulteriore, tornaconto politico, o incentivo nascosto. Per questo, potrebbe governare in maniera più produttiva e limpida rispetto a qualsiasi essere umano, per sua natura imperfetto.

## Dove si posiziona GPT-4 nella scala dei valori?

Ci sono alcuni valori che non sono necessariamente giusti o sbagliati, semplicemente diversi: cosa sceglierebbe di fare GPT-4 se gli fossero presentate diverse opzioni, tutte quante non necessariamente giuste o sbagliate?

Ad esempio, se GPT-4 fosse un giudice, che pena darebbe a una persona trovata in possesso di droghe leggere? E cosa farebbe se fosse un consulente aziendale incaricato di consigliare pratiche legali o immorali?

# Metodologia

L'esperimento è stato condotto in inglese con le API di GPT-4, senza messaggio di sistema. Tutti i messaggi, sia dell'utente che dell'AI, sono ripotati nel file `originali.txt`.

L'esperimento è stato condotto in inglese perché i risultati in questa lingua sono di maggiore qualità. La traduzione italiana è stata fatta in automatico da Google Translate, con alcune mie correzioni per gli errori più gravi di compresione. La traduzione italiana è nel file `italiano.txt`

Sono stati posti 5 scenari diversi a GPT-4. Ogni scenario è preceduto da un "priming" sempre uguale, ossia una serie di istruzioni generiche per dare il giusto contesto a GPT-4 prima di iniziare l'esperimento.

I miei commenti sulle risposte di GPT-4 sono sul mio canale Youtube. Video 1:

https://www.youtube.com/watch?v=s5XF8SIOHT8